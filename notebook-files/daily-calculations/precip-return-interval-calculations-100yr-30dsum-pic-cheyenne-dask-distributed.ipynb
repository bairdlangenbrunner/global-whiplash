{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:04:12.850681Z",
     "start_time": "2019-02-01T21:04:10.383069Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import xarray\n",
    "import matplotlib.pyplot as mp\n",
    "import glob\n",
    "import pandas\n",
    "import cartopy\n",
    "import itertools\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "import dask_jobqueue\n",
    "import dask.distributed\n",
    "import ipywidgets\n",
    "#import dask.diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful commands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# job specification in full (if not using .config/dask/*.yml file)\n",
    "cluster = dask_jobqueue.PBSCluster(cores=36,\n",
    "                                   memory='100 GB',\n",
    "                                   project='UCLA0022',\n",
    "                                   queue='regular',\n",
    "                                   walltime='00:30:00')\n",
    "                                   \n",
    "to close a cluster:\n",
    "num_workers = 20\n",
    "workers = cluster.scheduler.workers_to_close(n=num_workers)\n",
    "cluster.scheduler.retire_workers(workers=workers,close_workers=True,remove=True)\n",
    "\n",
    "to delete a cluster:\n",
    "del(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.PBSCluster(cores=36,\n",
    "                                   memory='100 GB',\n",
    "                                   project='UCLA0022',\n",
    "                                   queue='regular',\n",
    "                                   walltime='01:00:00',\n",
    "                                   local_directory='$TMPDIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for 30 workers with these specifications\n",
    "cluster.start_workers(50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!qstat -u baird\n",
    "\n",
    "!ls /glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/daily/PRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:04:12.854849Z",
     "start_time": "2019-02-01T21:04:12.852577Z"
    }
   },
   "outputs": [],
   "source": [
    "#PRECT_root = '/ninad/NCAR_LENS/PRECT/'\n",
    "#PRECT_root = '/scratch/blangenb/NCAR_LENS/PRECT/'\n",
    "PRECT_root =  '/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/daily/PRECT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open pre-industrial control as multi-file dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:04:15.888385Z",
     "start_time": "2019-02-01T21:04:15.144094Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'b.e11.B1850C5CN.f09_g16.005.cam.h1.PRECT.04020101-04991231.nc'\n",
    "example_pic_ds = xarray.open_dataset(PRECT_root + 'b.e11.B1850C5CN.f09_g16.005.cam.h1.PRECT.04020101-04991231.nc')\n",
    "lat_total = example_pic_ds['lat']\n",
    "lon_total = example_pic_ds['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:05:09.430727Z",
     "start_time": "2019-02-01T21:05:09.427878Z"
    }
   },
   "outputs": [],
   "source": [
    "filename_list = sorted(glob.glob('/glade/scratch/baird/global-whiplash-files/rolling_30day_sum*'))\n",
    "\n",
    "#mfds = xarray.open_mfdataset([filename_list[0]], chunks={'lat':24, 'lon':24})\n",
    "#mfds = xarray.open_mfdataset(filename_list[:10], chunks={'lat':24, 'lon':24})\n",
    "mfds = xarray.open_mfdataset(filename_list, chunks={'lat':24, 'lon':24})\n",
    "\n",
    "mfds_data = mfds['__xarray_dataarray_variable__']\n",
    "\n",
    "mfds_time = mfds['time'].values\n",
    "mfds_lat = mfds['lat'].values\n",
    "mfds_lon = mfds['lon'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfds_lat.shape, mfds_lon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pull out time and specific months\n",
    "2. calculate the number of days in those months\n",
    "3. other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:05:11.078143Z",
     "start_time": "2019-02-01T21:05:10.983661Z"
    }
   },
   "outputs": [],
   "source": [
    "event_size = 30 # days\n",
    "season = 'ONDJFM'; month_numbers = [10,11,12,1,2,3]\n",
    "time_data_indices = [t.month in month_numbers for t in mfds_time]\n",
    "\n",
    "ndays = sum([calendar.monthrange(1979,m)[1] for m in month_numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T21:05:11.342531Z",
     "start_time": "2019-02-01T21:05:11.339322Z"
    }
   },
   "outputs": [],
   "source": [
    "return_period = 100 # in years\n",
    "events_per_year = ndays/event_size #152/30\n",
    "\n",
    "return_val_perc = 100*(1-1/(return_period*events_per_year))\n",
    "return_val_fraction = (1-1/(return_period*events_per_year))\n",
    "print(return_val_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mfds size in GB {:0.2f}\\n'.format(mfds.nbytes / 1e9))\n",
    "mfds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKED ON SMALL DATA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# works only on SMALL data sets\n",
    "quantile_results = mfds_data.compute().quantile(dim='time', q=return_val_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRYING FOR LARGER DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfds_data = mfds_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perc(x, q=return_val_fraction):\n",
    "    return(numpy.nanpercentile(x, q=return_val_fraction, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doesn't compute things yet, just applies function to all chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dask.array.apply_along_axis(calc_perc, arr=mfds_data.data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_calculation = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.pcolormesh(perc_calculation*86400.*1000.)\n",
    "mp.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_da = xarray.DataArray(perc_calculation*86400.*1000., name='100yr_30dsum_return_values', \n",
    "                             coords={'lon':lon_total,'lat':lat_total},\n",
    "                             dims={'lat','lon'}, attrs={'units':'kg m s-1'})\n",
    "\n",
    "output_df = xarray.Dataset({'100yr_30dsum_return_values':output_da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_netcdf('pic_100yr_30dsum_return_values.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
