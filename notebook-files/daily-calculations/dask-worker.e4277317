distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.220:53352'
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.220:48907
distributed.worker - INFO -          Listening to:   tcp://10.148.7.220:48907
distributed.worker - INFO -              nanny at:         10.148.7.220:53352
distributed.worker - INFO -              bokeh at:         10.148.7.220:58232
distributed.worker - INFO - Waiting to connect to:  tcp://10.148.13.150:44940
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         36
distributed.worker - INFO -                Memory:                  100.00 GB
distributed.worker - INFO -       Local Directory: /var/tmp/pbs.4277317.chadmin1/worker-7ykdkxub
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://10.148.13.150:44940
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 11.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/distributed/worker.py", line 1356, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/distributed/worker.py", line 1548, in put_key_in_memory
    self.data[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/buffer.py", line 80, in __setitem__
    self.fast[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/lru.py", line 71, in __setitem__
    self.evict()
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/lru.py", line 90, in evict
    cb(k, v)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/buffer.py", line 52, in fast_to_slow
    self.slow[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/func.py", line 42, in __setitem__
    self.d[key] = self.dump(value)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/file.py", line 83, in __setitem__
    f.write(v)
OSError: [Errno 28] No space left on device
distributed.core - INFO - Event loop was unresponsive in Worker for 36.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/distributed/worker.py", line 1356, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/distributed/worker.py", line 1548, in put_key_in_memory
    self.data[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/buffer.py", line 80, in __setitem__
    self.fast[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/lru.py", line 71, in __setitem__
    self.evict()
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/lru.py", line 90, in evict
    cb(k, v)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/buffer.py", line 52, in fast_to_slow
    self.slow[key] = value
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/func.py", line 42, in __setitem__
    self.d[key] = self.dump(value)
  File "/glade/u/home/baird/miniconda3/envs/pangeo/lib/python3.7/site-packages/zict/file.py", line 83, in __setitem__
    f.write(v)
OSError: [Errno 28] No space left on device
distributed.worker - INFO - Can't find dependencies for key ('getitem-9b35b2fb40f7cc4a57eb77b82250a3fd', 3, 6, 2, 0)
distributed.worker - INFO - Dependent not found: ('func-overlap-getitem-9b35b2fb40f7cc4a57eb77b82250a3fd', 3, 6, 2, 0) 0 .  Asking scheduler
distributed.utils_perf - INFO - full garbage collection released 131.94 MB from 1397 reference cycles (threshold: 10.00 MB)
=>> PBS: job killed: walltime 10871 exceeded limit 10800
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.220:53352'
distributed.dask_worker - INFO - End worker
